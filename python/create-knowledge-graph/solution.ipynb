{
    "cells": [
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "# Create a Knowledge Graph from Text"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## Task 1: Import Libraries"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "import wikipedia\n",
       "import re\n",
       "import requests\n",
       "import spacy\n",
       "import spacy_transformers\n",
       "from spacy import displacy\n",
       "from spacy.matcher import Matcher\n",
       "import networkx as nx\n",
       "from pyvis.network import Network"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## Task 2: Load the Data"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
       "scrolled": true
      },
      "outputs": [],
      "source": [
       "wikipedia.set_lang('en')\n",
       "title = \" 'Maharana Pratap' \"\n",
       "data = wikipedia.page(title).content\n",
       "print(data)"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## Task 3: Preprocess the Data"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
       "scrolled": true
      },
      "outputs": [],
      "source": [
       "data = data.lower().replace('\\n', \"\")\n",
       "data = re.sub('== see also ==.*|[@#:&\\\"]|===.*?===|==.*?==|\\(.*?\\)', '', data)\n",
       "print(data)"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## Task 4: Recognize Named Entities"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
       "scrolled": true
      },
      "outputs": [],
      "source": [
       "nlp = spacy.load('en_core_web_lg')\n",
       "doc = nlp(data)\n",
       "\n",
       "displacy.render(doc, style=\"ent\", jupyter=True)"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## Task 5: Compute Coreference Clusters"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
       "scrolled": true
      },
      "outputs": [],
      "source": [
       "# nlp.add_pipe('coreferee')\n",
       "doc = nlp(data)\n",
       "\n",
       "doc._.coref_chains.print()"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## Task 6: Resolve Coreferences"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "resolved_data = \"\"\n",
       "for token in doc:\n",
       "    resolved_coref = doc._.coref_chains.resolve(token)\n",
       "    if resolved_coref:\n",
       "        resolved_data += \" \" + \" and \".join(r.text for r in resolved_coref)\n",
       "    elif token.dep_ == \"punct\":\n",
       "        resolved_data += token.text\n",
       "    else:\n",
       "        resolved_data += \" \" + token.text\n",
       "print(resolved_data)"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## Task 7: Extract Relationships"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "def extract_relationship(sentence):\n",
       "    doc = nlp(sentence)\n",
       "\n",
       "    first, last = None, None\n",
       "\n",
       "    for chunk in doc.noun_chunks:\n",
       "        if not first:\n",
       "            first = chunk\n",
       "        else:\n",
       "            last = chunk\n",
       "        \n",
       "    if first and last:\n",
       "        return (first.text.strip(), last.text.strip(), str(doc[first.end:last.start]).strip())\n",
       "\n",
       "    return (None, None, None)"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## Task 8: Create a Graph"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "#A helper function that prints 5 words per row. Can be used for better readability of a given text.\n",
       "print_five_words = lambda sentence: '\\n'.join(' '.join(sentence.split()[i:i+5]) for i in range(0, len(sentence.split()), 5))"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "graph_doc = nlp(resolved_data)\n",
       "\n",
       "nx_graph = nx.DiGraph()\n",
       "\n",
       "for sent in enumerate(graph_doc.sents):\n",
       "    if len(sent[1]) > 3:\n",
       "        (a, b, c) = extract_relationship(str(sent[1]))\n",
       "\n",
       "        if a and b:\n",
       "            nx_graph.add_node(a, size = 5)\n",
       "            nx_graph.add_node(b, size = 5)\n",
       "            nx_graph.add_edge(a, b, weight = 1, title = print_five_words(c), arrows=\"to\")\n",
       "\n",
       "g = Network(notebook=True, cdn_resources='in_line')\n",
       "g.from_nx(nx_graph)\n",
       "g.show(\"example.html\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## Task 9: List the Related Entities"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "\n",
       "print(nx_graph.edges(['pratap']))"
      ]
     }
    ],
    "metadata": {
     "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
     },
     "language_info": {
      "codemirror_mode": {
       "name": "ipython",
       "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
     },
     "vscode": {
      "interpreter": {
       "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
      }
     }
    },
    "nbformat": 4,
    "nbformat_minor": 4
   }